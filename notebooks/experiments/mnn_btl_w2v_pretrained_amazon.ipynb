{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.8.* in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from -r ../../requirements.txt (line 1)) (2.8.4)\n",
      "Requirement already satisfied: tensorflow-addons==0.18.0 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from -r ../../requirements.txt (line 2)) (0.18.0)\n",
      "Requirement already satisfied: wheel in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from -r ../../requirements.txt (line 3)) (0.40.0)\n",
      "Requirement already satisfied: pandas<2.0.0 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from -r ../../requirements.txt (line 4)) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from -r ../../requirements.txt (line 5)) (1.2.2)\n",
      "Requirement already satisfied: scipy in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from -r ../../requirements.txt (line 6)) (1.10.1)\n",
      "Requirement already satisfied: matplotlib in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from -r ../../requirements.txt (line 7)) (3.7.1)\n",
      "Requirement already satisfied: tqdm in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from -r ../../requirements.txt (line 8)) (4.65.0)\n",
      "Requirement already satisfied: Pillow in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from -r ../../requirements.txt (line 9)) (9.5.0)\n",
      "Requirement already satisfied: kaggle in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from -r ../../requirements.txt (line 10)) (1.5.13)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (23.5.26)\n",
      "Requirement already satisfied: gast>=0.2.1 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (3.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (16.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (4.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (0.32.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (1.54.2)\n",
      "Requirement already satisfied: packaging in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from tensorflow-addons==0.18.0->-r ../../requirements.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorflow-addons==0.18.0->-r ../../requirements.txt (line 2)) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from pandas<2.0.0->-r ../../requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from pandas<2.0.0->-r ../../requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from scikit-learn->-r ../../requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from scikit-learn->-r ../../requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from matplotlib->-r ../../requirements.txt (line 7)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from matplotlib->-r ../../requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from matplotlib->-r ../../requirements.txt (line 7)) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from matplotlib->-r ../../requirements.txt (line 7)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from matplotlib->-r ../../requirements.txt (line 7)) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from matplotlib->-r ../../requirements.txt (line 7)) (5.12.0)\n",
      "Requirement already satisfied: certifi in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from kaggle->-r ../../requirements.txt (line 10)) (2023.5.7)\n",
      "Requirement already satisfied: requests in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from kaggle->-r ../../requirements.txt (line 10)) (2.31.0)\n",
      "Requirement already satisfied: python-slugify in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from kaggle->-r ../../requirements.txt (line 10)) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from kaggle->-r ../../requirements.txt (line 10)) (1.26.16)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->-r ../../requirements.txt (line 7)) (3.15.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (2.3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from requests->kaggle->-r ../../requirements.txt (line 10)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from requests->kaggle->-r ../../requirements.txt (line 10)) (3.4)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from typeguard>=2.7->tensorflow-addons==0.18.0->-r ../../requirements.txt (line 2)) (6.6.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from python-slugify->kaggle->-r ../../requirements.txt (line 10)) (1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /pfs/data5/home/es/es_es/es_kamait02/miniconda3/envs/tf2.8/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /pfs/data5/home/es/es_es/es_kamait02/.local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.*->-r ../../requirements.txt (line 1)) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add directory above current directory to path\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from utils.text_processing import CharTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 15:30:52.736204: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 15:30:53.290160: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-06-14 15:30:53.290213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30967 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.get_memory_info(\"GPU:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(\"./configs/mnn_btl_w2v_pretrained_amazon.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader.abo import ABO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading abo-listings.tar...\n",
      "abo-listings.tar already exists.\n",
      "Downloading abo-images-small.tar...\n",
      "abo-images-small.tar already exists.\n",
      "Loading images...\n",
      "Loading texts...\n",
      "Importing listings CSV...\n",
      "Creating false samples/complement...\n",
      "Merging ground truth and complement...\n",
      "Concatenating attributes into description columns...\n",
      "Finishing up...\n",
      "Exporting to CSV...\n",
      "Data processing complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>path</th>\n",
       "      <th>product_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mobile coverb07tf1bkqyamazon brand - solimo de...</td>\n",
       "      <td>42/423d10f4.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>back coverb0856bygtgamazon brand - solimo desi...</td>\n",
       "      <td>9c/9cf1dd23.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mobile coverb07t9tn394amazon brand - solimo de...</td>\n",
       "      <td>30/30126ff7.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobile coverb07sp4hfwfamazon brand - solimo de...</td>\n",
       "      <td>1b/1bc5782f.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobile coverb075ylrjlpamazon brand: find drive...</td>\n",
       "      <td>a8/a8746f69.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168173</th>\n",
       "      <td>mobile coverb07tqh6zlfamazon brand - solimo de...</td>\n",
       "      <td>52/520ada11.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168174</th>\n",
       "      <td>mobile coverb081hnqj2hamazon brand - solimo de...</td>\n",
       "      <td>7a/7a349abb.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168175</th>\n",
       "      <td>mobile coverb081hmx7msamazon brand - solimo de...</td>\n",
       "      <td>37/3751f5bb.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168176</th>\n",
       "      <td>amazon brand - solimob07xvpttvfamazon brand - ...</td>\n",
       "      <td>d9/d9a98067.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168177</th>\n",
       "      <td>mobile coverb081hn1l81amazon brand - solimo de...</td>\n",
       "      <td>ca/cafe82aa.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168178 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description             path  \\\n",
       "0       mobile coverb07tf1bkqyamazon brand - solimo de...  42/423d10f4.jpg   \n",
       "1       back coverb0856bygtgamazon brand - solimo desi...  9c/9cf1dd23.jpg   \n",
       "2       mobile coverb07t9tn394amazon brand - solimo de...  30/30126ff7.jpg   \n",
       "3       mobile coverb07sp4hfwfamazon brand - solimo de...  1b/1bc5782f.jpg   \n",
       "4       mobile coverb075ylrjlpamazon brand: find drive...  a8/a8746f69.jpg   \n",
       "...                                                   ...              ...   \n",
       "168173  mobile coverb07tqh6zlfamazon brand - solimo de...  52/520ada11.jpg   \n",
       "168174  mobile coverb081hnqj2hamazon brand - solimo de...  7a/7a349abb.jpg   \n",
       "168175  mobile coverb081hmx7msamazon brand - solimo de...  37/3751f5bb.jpg   \n",
       "168176  amazon brand - solimob07xvpttvfamazon brand - ...  d9/d9a98067.jpg   \n",
       "168177  mobile coverb081hn1l81amazon brand - solimo de...  ca/cafe82aa.jpg   \n",
       "\n",
       "               product_type  label  \n",
       "0       CELLULAR_PHONE_CASE      1  \n",
       "1       CELLULAR_PHONE_CASE      1  \n",
       "2       CELLULAR_PHONE_CASE      1  \n",
       "3       CELLULAR_PHONE_CASE      0  \n",
       "4       CELLULAR_PHONE_CASE      0  \n",
       "...                     ...    ...  \n",
       "168173  CELLULAR_PHONE_CASE      0  \n",
       "168174  CELLULAR_PHONE_CASE      1  \n",
       "168175  CELLULAR_PHONE_CASE      0  \n",
       "168176  CELLULAR_PHONE_CASE      1  \n",
       "168177  CELLULAR_PHONE_CASE      1  \n",
       "\n",
       "[168178 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ABO(path=config[\"data\"][\"path\"],\n",
    "           download=True,\n",
    "           extract=False,\n",
    "           preprocess=True,\n",
    "           alt_augment=False,\n",
    "           random_deletion=False,\n",
    "           export_csv=True).data\n",
    "\n",
    "# data = pd.read_csv(os.path.join(config[\"data\"][\"path\"], \"data.csv\"))\n",
    "# data = data.drop({\"Unnamed: 0\"}, axis=1)\n",
    "\n",
    "data = data[['description', 'path', 'product_type', 'label']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data[[\"path\"]]  # two brackets for keeping the column name\n",
    "text = data[\"description\"]\n",
    "product_types = data[[\"product_type\"]]\n",
    "labels = data[[\"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/fse/word2vec-google-news-300\n",
    "\n",
    "Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. The phrases were obtained using a simple data-driven approach described in 'Distributed Representations of Words and Phrases and their Compositionality' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_pretrained_model = KeyedVectors.load(f'./word2vec-google-news-300/word2vec-google-news-300.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vectors = np.load(f'./word2vec-google-news-300/word2vec-google-news-300.model.vectors.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=None, output_sequence_length=300)\n",
    "\n",
    "vectorizer.adapt(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168178, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = vectorizer(text).numpy()\n",
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'mobile',\n",
       " 'back',\n",
       " 'brand',\n",
       " 'for',\n",
       " 'solimo',\n",
       " 'cover',\n",
       " 'case',\n",
       " 'designer']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "voc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 8965 words (155172 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if w2v_pretrained_model.has_index_for(word):\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = w2v_pretrained_model.get_vector(word, norm=True)\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W2V Google Embedding only converts less than 10% of data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.img_processing import load_img_model, create_embeddings_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 576)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_model = load_img_model(config[\"img_model\"])\n",
    "\n",
    "img_model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mobilenetv3small:\n",
    "# batch_size = 1024 -> 8 GB VRAM\n",
    "# batch_size = 2048 -> 16 GB VRAM\n",
    "# ...\n",
    "# Mobilenetv3large: twice as much as Mobilenetv3small\n",
    "\n",
    "img = create_embeddings_from(img_model,\n",
    "                             img,\n",
    "                             os.path.join(config[\"data\"][\"path\"],\n",
    "                                          \"images/small\"),\n",
    "                             batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(config[\"data\"][\"path\"],\n",
    "                         f\"embeddings/w2v_pretrained/{img_model.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_path, exist_ok=True)\n",
    "np.save(f\"{save_path}/img.npy\", img)\n",
    "np.save(f\"{save_path}/text.npy\", text)\n",
    "data.to_csv(f\"{save_path}/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>path</th>\n",
       "      <th>product_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surface cleanerb07zkpz5m9amazon brand - presto...</td>\n",
       "      <td>11/11fcff6f.jpg</td>\n",
       "      <td>HEALTH_PERSONAL_CARE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobile coverb07tcwt6qzamazon brand - solimo de...</td>\n",
       "      <td>6d/6d467c22.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clear caseb08569tz7mamazon brand  rivet geomet...</td>\n",
       "      <td>ae/ae7772de.jpg</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grocery &amp; gourmet food beverages bottled bever...</td>\n",
       "      <td>97/97abbdae.jpg</td>\n",
       "      <td>JUICE_AND_JUICE_DRINK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back coverb08569h3s9amazon brand - solimo desi...</td>\n",
       "      <td>18/18096140.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168180</th>\n",
       "      <td>mobile coverb08569ppwramazonbasics metal monit...</td>\n",
       "      <td>17/17f2fb25.jpg</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168181</th>\n",
       "      <td>not applicableb07wny6fhfamazon essentials wome...</td>\n",
       "      <td>db/db20fd35.jpg</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168182</th>\n",
       "      <td>mobile coverb07th14222strathwood chaise lounge...</td>\n",
       "      <td>6d/6dc131cd.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168183</th>\n",
       "      <td>stuffingb07jlz7qc7amazon brand  rivet contempo...</td>\n",
       "      <td>ac/acec2689.jpg</td>\n",
       "      <td>PILLOW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168184</th>\n",
       "      <td>mobile coverb07th3t98samazon brand - solimo de...</td>\n",
       "      <td>b7/b75310cf.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168185 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description             path  \\\n",
       "0       surface cleanerb07zkpz5m9amazon brand - presto...  11/11fcff6f.jpg   \n",
       "1       mobile coverb07tcwt6qzamazon brand - solimo de...  6d/6d467c22.jpg   \n",
       "2       clear caseb08569tz7mamazon brand  rivet geomet...  ae/ae7772de.jpg   \n",
       "3       grocery & gourmet food beverages bottled bever...  97/97abbdae.jpg   \n",
       "4       back coverb08569h3s9amazon brand - solimo desi...  18/18096140.jpg   \n",
       "...                                                   ...              ...   \n",
       "168180  mobile coverb08569ppwramazonbasics metal monit...  17/17f2fb25.jpg   \n",
       "168181  not applicableb07wny6fhfamazon essentials wome...  db/db20fd35.jpg   \n",
       "168182  mobile coverb07th14222strathwood chaise lounge...  6d/6dc131cd.jpg   \n",
       "168183  stuffingb07jlz7qc7amazon brand  rivet contempo...  ac/acec2689.jpg   \n",
       "168184  mobile coverb07th3t98samazon brand - solimo de...  b7/b75310cf.jpg   \n",
       "\n",
       "                 product_type  label  \n",
       "0        HEALTH_PERSONAL_CARE      1  \n",
       "1         CELLULAR_PHONE_CASE      1  \n",
       "2                     GROCERY      0  \n",
       "3       JUICE_AND_JUICE_DRINK      1  \n",
       "4         CELLULAR_PHONE_CASE      1  \n",
       "...                       ...    ...  \n",
       "168180                  SHOES      0  \n",
       "168181                  SHOES      1  \n",
       "168182    CELLULAR_PHONE_CASE      0  \n",
       "168183                 PILLOW      1  \n",
       "168184    CELLULAR_PHONE_CASE      1  \n",
       "\n",
       "[168185 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f\"{save_path}/data.csv\")\n",
    "data = data.drop({\"Unnamed: 0\"}, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168185, 576)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.load(f\"{save_path}/img.npy\", allow_pickle=True)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168185, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = np.load(f\"{save_path}/text.npy\", allow_pickle=True)\n",
    "text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into ground truth/false samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `stratify` parameter of `sklearn.model_selection.train_test_split()`, we need to select all product instances which appear more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>path</th>\n",
       "      <th>product_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surface cleanerb07zkpz5m9amazon brand - presto...</td>\n",
       "      <td>11/11fcff6f.jpg</td>\n",
       "      <td>HEALTH_PERSONAL_CARE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobile coverb07tcwt6qzamazon brand - solimo de...</td>\n",
       "      <td>6d/6d467c22.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grocery &amp; gourmet food beverages bottled bever...</td>\n",
       "      <td>97/97abbdae.jpg</td>\n",
       "      <td>JUICE_AND_JUICE_DRINK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>back coverb08569h3s9amazon brand - solimo desi...</td>\n",
       "      <td>18/18096140.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mobile coverb07t22xb8damazon brand - solimo de...</td>\n",
       "      <td>37/3772efa6.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168176</th>\n",
       "      <td>cellphonecoverb08569yts4amazon brand - solimo ...</td>\n",
       "      <td>11/11e67bd1.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168177</th>\n",
       "      <td>cellphonecoverb0853xkskvamazon brand - solimo ...</td>\n",
       "      <td>d7/d79173cf.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168181</th>\n",
       "      <td>not applicableb07wny6fhfamazon essentials wome...</td>\n",
       "      <td>db/db20fd35.jpg</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168183</th>\n",
       "      <td>stuffingb07jlz7qc7amazon brand  rivet contempo...</td>\n",
       "      <td>ac/acec2689.jpg</td>\n",
       "      <td>PILLOW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168184</th>\n",
       "      <td>mobile coverb07th3t98samazon brand - solimo de...</td>\n",
       "      <td>b7/b75310cf.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87380 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description             path  \\\n",
       "0       surface cleanerb07zkpz5m9amazon brand - presto...  11/11fcff6f.jpg   \n",
       "1       mobile coverb07tcwt6qzamazon brand - solimo de...  6d/6d467c22.jpg   \n",
       "3       grocery & gourmet food beverages bottled bever...  97/97abbdae.jpg   \n",
       "4       back coverb08569h3s9amazon brand - solimo desi...  18/18096140.jpg   \n",
       "7       mobile coverb07t22xb8damazon brand - solimo de...  37/3772efa6.jpg   \n",
       "...                                                   ...              ...   \n",
       "168176  cellphonecoverb08569yts4amazon brand - solimo ...  11/11e67bd1.jpg   \n",
       "168177  cellphonecoverb0853xkskvamazon brand - solimo ...  d7/d79173cf.jpg   \n",
       "168181  not applicableb07wny6fhfamazon essentials wome...  db/db20fd35.jpg   \n",
       "168183  stuffingb07jlz7qc7amazon brand  rivet contempo...  ac/acec2689.jpg   \n",
       "168184  mobile coverb07th3t98samazon brand - solimo de...  b7/b75310cf.jpg   \n",
       "\n",
       "                 product_type  label  \n",
       "0        HEALTH_PERSONAL_CARE      1  \n",
       "1         CELLULAR_PHONE_CASE      1  \n",
       "3       JUICE_AND_JUICE_DRINK      1  \n",
       "4         CELLULAR_PHONE_CASE      1  \n",
       "7         CELLULAR_PHONE_CASE      1  \n",
       "...                       ...    ...  \n",
       "168176    CELLULAR_PHONE_CASE      1  \n",
       "168177    CELLULAR_PHONE_CASE      1  \n",
       "168181                  SHOES      1  \n",
       "168183                 PILLOW      1  \n",
       "168184    CELLULAR_PHONE_CASE      1  \n",
       "\n",
       "[87380 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = data[data[\"label\"] == 1]\n",
    "false_samples = data[data[\"label\"] == 0]\n",
    "data = ground_truth\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>path</th>\n",
       "      <th>product_type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clear caseb08569tz7mamazon brand  rivet geomet...</td>\n",
       "      <td>ae/ae7772de.jpg</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mobile coverb07t8114tkchoco-cran cherry trail ...</td>\n",
       "      <td>ae/ae2d64e3.jpg</td>\n",
       "      <td>ACCESSORY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mobile coverb0853x7fbhamazon brand - solimo de...</td>\n",
       "      <td>33/330b137e.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mobile coverb07qkgcvf4whole foods market, esse...</td>\n",
       "      <td>70/7003df63.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>apple iphone xr mobile back case cover transpa...</td>\n",
       "      <td>16/165be3da.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168174</th>\n",
       "      <td>back coverb07th2zwqk365 everyday value organic...</td>\n",
       "      <td>bb/bb89c89d.jpg</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168178</th>\n",
       "      <td>back coverb07th3zyr3amazon brand - solimo desi...</td>\n",
       "      <td>ac/ac1f2d24.jpg</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168179</th>\n",
       "      <td>mobile coverb07tg4rtzdamazon brand - symbol me...</td>\n",
       "      <td>4b/4b8de49c.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168180</th>\n",
       "      <td>mobile coverb08569ppwramazonbasics metal monit...</td>\n",
       "      <td>17/17f2fb25.jpg</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168182</th>\n",
       "      <td>mobile coverb07th14222strathwood chaise lounge...</td>\n",
       "      <td>6d/6dc131cd.jpg</td>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80805 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description             path  \\\n",
       "2       clear caseb08569tz7mamazon brand  rivet geomet...  ae/ae7772de.jpg   \n",
       "5       mobile coverb07t8114tkchoco-cran cherry trail ...  ae/ae2d64e3.jpg   \n",
       "6       mobile coverb0853x7fbhamazon brand - solimo de...  33/330b137e.jpg   \n",
       "9       mobile coverb07qkgcvf4whole foods market, esse...  70/7003df63.jpg   \n",
       "11      apple iphone xr mobile back case cover transpa...  16/165be3da.jpg   \n",
       "...                                                   ...              ...   \n",
       "168174  back coverb07th2zwqk365 everyday value organic...  bb/bb89c89d.jpg   \n",
       "168178  back coverb07th3zyr3amazon brand - solimo desi...  ac/ac1f2d24.jpg   \n",
       "168179  mobile coverb07tg4rtzdamazon brand - symbol me...  4b/4b8de49c.jpg   \n",
       "168180  mobile coverb08569ppwramazonbasics metal monit...  17/17f2fb25.jpg   \n",
       "168182  mobile coverb07th14222strathwood chaise lounge...  6d/6dc131cd.jpg   \n",
       "\n",
       "               product_type  label  \n",
       "2                   GROCERY      0  \n",
       "5                 ACCESSORY      0  \n",
       "6       CELLULAR_PHONE_CASE      0  \n",
       "9       CELLULAR_PHONE_CASE      0  \n",
       "11      CELLULAR_PHONE_CASE      0  \n",
       "...                     ...    ...  \n",
       "168174                SHOES      0  \n",
       "168178                SHOES      0  \n",
       "168179  CELLULAR_PHONE_CASE      0  \n",
       "168180                SHOES      0  \n",
       "168182  CELLULAR_PHONE_CASE      0  \n",
       "\n",
       "[80805 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_false = img[false_samples.index]\n",
    "text_false = text[false_samples.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[data.index]\n",
    "text = text[data.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "false_samples = false_samples.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87380, 576)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80805, 576)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_false.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"product_type_count\"] = data.groupby(\n",
    "    [\"product_type\"])[\"product_type\"].transform(\"count\")\n",
    "\n",
    "data = data[data[\"product_type_count\"] > config[\"data\"][\"cls\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update both columns\n",
    "product_types = data[[\"product_type\"]]\n",
    "\n",
    "labels = data[[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, product_types_train, product_types_test = train_test_split(\n",
    "    data,\n",
    "    product_types,\n",
    "    stratify=product_types,\n",
    "    test_size=config[\"model\"][\"training\"][\"test_split\"],\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = img[train.index]\n",
    "img_test = img[test.index]\n",
    "\n",
    "text_train = text[train.index]\n",
    "text_test = text[test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_samples[\"product_type_count\"] = false_samples.groupby(\n",
    "    [\"product_type\"])[\"product_type\"].transform(\"count\")\n",
    "\n",
    "false_samples = false_samples[false_samples[\"product_type_count\"] > config[\"data\"][\"cls\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update both columns\n",
    "product_types_false = false_samples[[\"product_type\"]]\n",
    "\n",
    "labels_false = false_samples[[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_false, test_false, product_types_train_false, product_types_test_false = train_test_split(\n",
    "    false_samples,\n",
    "    product_types_false,\n",
    "    stratify=product_types_false,\n",
    "    test_size=config[\"model\"][\"training\"][\"test_split\"],\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_false = img_false[train_false.index]\n",
    "img_test_false = img_false[test_false.index]\n",
    "\n",
    "text_train_false = text_false[train_false.index]\n",
    "text_test_false = text_false[test_false.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build MNN-BTL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import create_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_config = {\n",
    "    \"img_input_size\": img_model.layers[-1].output_shape[1],\n",
    "    \"txt_input_size\": embedding_dim,\n",
    "    \"img_fc_layers\": config[\"model\"][\"img_fc_layers\"],\n",
    "    \"txt_fc_layers\": config[\"model\"][\"txt_fc_layers\"],\n",
    "    \"extended\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Concatenate, Embedding, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from models.mnn_em import _CNNBranch\n",
    "from models.addons.tensorflow_addons.losses import triplet_multimodal\n",
    "\n",
    "\n",
    "class MNNBTLWord2VecPretrained(object):\n",
    "    def __init__(self, head_config, learning_rate, name=\"MNN_BTL\"):\n",
    "        self.head_config = head_config\n",
    "        self.learning_rate = learning_rate\n",
    "        self.name = name\n",
    "        self._build_model()  # builds self.model variable\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Text Input\n",
    "        img_features = Input(shape=(self.head_config[\"img_input_size\"]),\n",
    "                             name=\"Image_Input_Head_Outer\")\n",
    "\n",
    "        img_cnn = _CNNBranch(self.head_config[\"img_input_size\"],\n",
    "                             self.head_config[\"img_fc_layers\"], self.head_config[\"extended\"], True, name=\"Image\")\n",
    "\n",
    "        # Image Input\n",
    "        text_features = Input(shape=(self.head_config[\"txt_input_size\"]), dtype=tf.int64, name=\"Text_Input_Head_Outer\")\n",
    "\n",
    "        embedding_layer = Embedding(\n",
    "            num_tokens,\n",
    "            self.head_config[\"txt_input_size\"],\n",
    "            embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "            trainable=False,\n",
    "        )\n",
    "\n",
    "        x = embedding_layer(text_features)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        text_branch = _CNNBranch(x.shape[1],\n",
    "                                 self.head_config[\"txt_fc_layers\"], self.head_config[\"extended\"], True, name=\"Text\")\n",
    "\n",
    "        output_text_branch = text_branch.model(x)\n",
    "\n",
    "        text_cnn = Model(inputs=text_features,\n",
    "                         outputs=output_text_branch, name=\"Text_CNN\")\n",
    "\n",
    "        model = Model(inputs=[img_features, text_features],\n",
    "                      outputs=Concatenate()(\n",
    "                          [img_cnn.model(img_features), text_cnn(text_features)]),\n",
    "                      name=self.name)\n",
    "\n",
    "        optimizer = Adam(learning_rate=self.learning_rate)\n",
    "\n",
    "        loss = triplet_multimodal.MultimodalTripletHardLossBidirectional(\n",
    "            distance_metric=\"angular\")\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss)\n",
    "\n",
    "        self.model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnn_btl = MNNBTLWord2VecPretrained(\n",
    "    head_config=head_config,\n",
    "    learning_rate=config[\"model\"][\"training\"][\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MNN_BTL\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Image_Input_Head_Outer (InputL  [(None, 576)]       0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " Text_Input_Head_Outer (InputLa  [(None, 300)]       0           []                               \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " Image_CNN (Functional)         (None, 512)          1115648     ['Image_Input_Head_Outer[0][0]'] \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| Image_Input_Head_Inner (InputL  [(None, 576)]     0           []                               |\n",
      "| ayer)                                                                                          |\n",
      "|                                                                                                |\n",
      "| Image_FC_1 (Dense)           (None, 1024)         590848      []                               |\n",
      "|                                                                                                |\n",
      "| Image_FC_last (Dense)        (None, 512)          524800      []                               |\n",
      "|                                                                                                |\n",
      "| Image_L2_Norm (Lambda)       (None, 512)          0           []                               |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " Text_CNN (Functional)          (None, 512)          141927524   ['Text_Input_Head_Outer[0][0]']  \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| Text_Input_Head_Outer (InputLa  [(None, 300)]     0           []                               |\n",
      "| yer)                                                                                           |\n",
      "|                                                                                                |\n",
      "| embedding_1 (Embedding)      (None, 300, 300)     49241700    []                               |\n",
      "|                                                                                                |\n",
      "| flatten (Flatten)            (None, 90000)        0           []                               |\n",
      "|                                                                                                |\n",
      "| Text_CNN (Functional)        (None, 512)          92685824    []                               |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| Text_Input_Head_Inner (InputLa  [(None, 90000)]  0          []                               ||\n",
      "|| yer)                                                                                         ||\n",
      "||                                                                                              ||\n",
      "|| Text_FC_1 (Dense)          (None, 1024)         92161024    []                               ||\n",
      "||                                                                                              ||\n",
      "|| Text_FC_last (Dense)       (None, 512)          524800      []                               ||\n",
      "||                                                                                              ||\n",
      "|| Text_L2_Norm (Lambda)      (None, 512)          0           []                               ||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " concatenate (Concatenate)      (None, 1024)         0           ['Image_CNN[0][0]',              \n",
      "                                                                  'Text_CNN[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,043,172\n",
      "Trainable params: 93,801,472\n",
      "Non-trainable params: 49,241,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnn_btl.model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# \"Head\"\n",
    "\n",
    "tf.keras.utils.plot_model(mnn_btl.model,\n",
    "                          rankdir=\"TB\",\n",
    "                          show_layer_activations=True,\n",
    "                          show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import create_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = config[\"model\"][\"training\"][\"log_dir\"]\n",
    "model_name = config[\"model\"][\"name\"]\n",
    "optimizer_name = config[\"model\"][\"training\"][\"optimizer\"]\n",
    "learning_rate = config[\"model\"][\"training\"][\"learning_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = create_callbacks(\n",
    "    callbacks_list=config[\"model\"][\"training\"][\"callbacks\"],\n",
    "    log_dir=log_dir,\n",
    "    model_name=model_name,\n",
    "    img_model_name=img_model.name,\n",
    "    optimizer_name=optimizer_name,\n",
    "    learning_rate=learning_rate,\n",
    "    cls=config[\"data\"][\"cls\"],\n",
    "    patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                 classes=product_types_train[\"product_type\"].unique(),\n",
    "                                                 y=product_types_train[\"product_type\"])\n",
    "len(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights_dict = {}\n",
    "class_weights_dict_transform = {}\n",
    "i = 0\n",
    "\n",
    "for pt, cw in zip(product_types_train[\"product_type\"].unique(), class_weights):\n",
    "    class_weights_dict[i] = cw\n",
    "    class_weights_dict_transform[pt] = i\n",
    "    i += 1\n",
    "    \n",
    "len(class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_weights_dict_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_type_transform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35648</th>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63708</th>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21828</th>\n",
       "      <td>RUG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51689</th>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32213</th>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63899</th>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34141</th>\n",
       "      <td>CELLULAR_PHONE_CASE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42676</th>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65232</th>\n",
       "      <td>SCREEN_PROTECTOR</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69848</th>\n",
       "      <td>KITCHEN</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78562 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              product_type  product_type_transform\n",
       "35648  CELLULAR_PHONE_CASE                       0\n",
       "63708  CELLULAR_PHONE_CASE                       0\n",
       "21828                  RUG                       1\n",
       "51689  CELLULAR_PHONE_CASE                       0\n",
       "32213  CELLULAR_PHONE_CASE                       0\n",
       "...                    ...                     ...\n",
       "63899  CELLULAR_PHONE_CASE                       0\n",
       "34141  CELLULAR_PHONE_CASE                       0\n",
       "42676               BEAUTY                      40\n",
       "65232     SCREEN_PROTECTOR                      46\n",
       "69848              KITCHEN                      48\n",
       "\n",
       "[78562 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_types_train[\"product_type_transform\"] = product_types_train[\"product_type\"].apply(lambda x: class_weights_dict_transform[x])\n",
    "product_types_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003965354505579923"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4417/4420 [============================>.] - ETA: 0s - loss: 0.6161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 15:33:19.238706: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Image_Input_Head_Outer, Text_Input_Head_Outer with unsupported characters which will be renamed to image_input_head_outer, text_input_head_outer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4420/4420 [==============================] - 128s 28ms/step - loss: 0.6159 - val_loss: 0.0268\n",
      "Epoch 2/10\n",
      "4414/4420 [============================>.] - ETA: 0s - loss: 0.0250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Image_Input_Head_Outer, Text_Input_Head_Outer with unsupported characters which will be renamed to image_input_head_outer, text_input_head_outer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4420/4420 [==============================] - 126s 29ms/step - loss: 0.0250 - val_loss: 0.0261\n",
      "Epoch 3/10\n",
      "4414/4420 [============================>.] - ETA: 0s - loss: 0.0241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Image_Input_Head_Outer, Text_Input_Head_Outer with unsupported characters which will be renamed to image_input_head_outer, text_input_head_outer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4420/4420 [==============================] - 125s 28ms/step - loss: 0.0241 - val_loss: 0.0242\n",
      "Epoch 4/10\n",
      "4416/4420 [============================>.] - ETA: 0s - loss: 0.0232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Image_Input_Head_Outer, Text_Input_Head_Outer with unsupported characters which will be renamed to image_input_head_outer, text_input_head_outer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4420/4420 [==============================] - 124s 28ms/step - loss: 0.0232 - val_loss: 0.0235\n",
      "Epoch 5/10\n",
      "4418/4420 [============================>.] - ETA: 0s - loss: 0.0227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Image_Input_Head_Outer, Text_Input_Head_Outer with unsupported characters which will be renamed to image_input_head_outer, text_input_head_outer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4420/4420 [==============================] - 125s 28ms/step - loss: 0.0227 - val_loss: 0.0233\n",
      "Epoch 6/10\n",
      "4420/4420 [==============================] - 32s 7ms/step - loss: 0.0223 - val_loss: 0.0248\n",
      "Epoch 7/10\n",
      "4419/4420 [============================>.] - ETA: 0s - loss: 0.0222"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Image_Input_Head_Outer, Text_Input_Head_Outer with unsupported characters which will be renamed to image_input_head_outer, text_input_head_outer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./runs/models/MNN_BTL_w2v_pretrained_ABO/cls_1/MobilenetV3small/Adam/lr_0.0001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4420/4420 [==============================] - 124s 28ms/step - loss: 0.0222 - val_loss: 0.0227\n",
      "Epoch 8/10\n",
      "4420/4420 [==============================] - 33s 7ms/step - loss: 0.0219 - val_loss: 0.0249\n",
      "Epoch 9/10\n",
      "4420/4420 [==============================] - 33s 7ms/step - loss: 0.0215 - val_loss: 0.0228\n",
      "Epoch 10/10\n",
      "4420/4420 [==============================] - 33s 7ms/step - loss: 0.0214 - val_loss: 0.0235\n"
     ]
    }
   ],
   "source": [
    "history = mnn_btl.model.fit(\n",
    "    x=[img_train, text_train],\n",
    "    y=product_types_train[\"product_type_transform\"],\n",
    "    epochs=config[\"model\"][\"training\"][\"epochs\"],\n",
    "    validation_split=config[\"model\"][\"training\"][\"validation_split\"],\n",
    "    batch_size=config[\"model\"][\"training\"][\"batch_size\"],\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import plot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history.history, [],\n",
    "             model_name, img_model.name, optimizer_name, learning_rate,\n",
    "             config[\"data\"][\"cls\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model and save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16803, 5) (16803, 576) (16803, 300)\n"
     ]
    }
   ],
   "source": [
    "test_merged = pd.concat([test.reset_index(drop=True), test_false.reset_index(drop=True)])\n",
    "img_test_merged = np.concatenate([img_test, img_test_false])\n",
    "text_test_merged = np.concatenate([text_test, text_test_false])\n",
    "print(test_merged.shape, img_test_merged.shape, text_test_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16803/16803 [==============================] - 17s 1ms/step - loss: 0.0699\n"
     ]
    }
   ],
   "source": [
    "evaluate(mnn_btl.model, [img_test_merged, text_test_merged], test_merged[[\"label\"]], log_dir, model_name,\n",
    "         img_model.name, optimizer_name, learning_rate, config[\"data\"][\"cls\"], triplet_model=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
